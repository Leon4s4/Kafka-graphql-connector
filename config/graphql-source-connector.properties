# GraphQL Source Connector Configuration Template
# Copy this file and customize the values for your specific use case

# Connector name (must be unique)
name=graphql-source-connector

# Connector class
connector.class=com.example.graphqlconnector.GraphQLSourceConnector

# Number of tasks to run (typically 1 for source connectors)
tasks.max=1

# Required Configuration
# =====================

# GraphQL API endpoint URL
graphql.endpoint.url=https://api.example.com/graphql

# Full GraphQL query with pagination variables ($first, $after)
# Example for Relay-style cursor pagination:
graphql.query=query GetUsers($first: Int!, $after: String) { users(first: $first, after: $after) { edges { node { id name email createdAt profile { avatar bio } } cursor } pageInfo { hasNextPage endCursor } } }

# JSONPath to extract data records from GraphQL response
# Default works with Relay-style pagination (edges/node pattern)
data.path=*.edges[*].node

# Response Parsing Configuration
# =============================

# JSONPath to extract pagination cursor for next page
pagination.cursor.path=*.pageInfo.endCursor

# JSONPath to extract hasMore flag for pagination
pagination.hasmore.path=*.pageInfo.hasNextPage

# JSONPath to extract record key from each data record (for Kafka record key)
record.key.path=id

# Optional Configuration
# ======================

# Additional GraphQL query variables as JSON object
# Example: {"status": "ACTIVE", "category": "premium"}
graphql.variables={}

# Custom HTTP headers for GraphQL requests (format: key1:value1,key2:value2)
# Example for Bearer token authentication:
# graphql.headers=Authorization:Bearer your-token-here,Content-Type:application/json
graphql.headers=

# Number of records to request per GraphQL query (pagination size)
result.size=100

# Interval between queries in milliseconds (default: 30000 = 30 seconds)
polling.interval.ms=30000

# Kafka topic name where records will be published (required)
kafka.topic.name=

# Timeout for GraphQL queries in milliseconds (default: 30000 = 30 seconds)  
query.timeout.ms=30000

# Maximum number of retry attempts for failed queries (default: 3)
max.retries=3

# Backoff time between retry attempts in milliseconds (default: 1000 = 1 second)
retry.backoff.ms=1000

# Kafka Configuration
# ===================

# Serialization (usually handled by Kafka Connect framework)
key.converter=org.apache.kafka.connect.storage.StringConverter
value.converter=org.apache.kafka.connect.json.JsonConverter
value.converter.schemas.enable=true

# Error handling
errors.retry.timeout=300000
errors.retry.delay.max.ms=60000
errors.tolerance=none

# Advanced Configuration Examples
# ===============================

# Example 1: Custom pagination pattern (offset-based)
# graphql.query=query GetItems($limit: Int!, $offset: Int!) { items(limit: $limit, offset: $offset) { data { id name } totalCount hasMore nextOffset } }
# data.path=items.data[*]
# pagination.cursor.path=items.nextOffset
# pagination.hasmore.path=items.hasMore

# Example 2: Multiple entities in single query
# graphql.query=query GetData($first: Int!, $after: String) { users: allUsers(first: $first, after: $after) { edges { node { ...UserFields } cursor } pageInfo { hasNextPage endCursor } } } fragment UserFields on User { id name email }
# data.path=users.edges[*].node

# Example 3: Nested data extraction
# graphql.query=query GetPosts($first: Int!, $after: String) { posts(first: $first, after: $after) { edges { node { id title author { id name } comments(first: 3) { edges { node { id text } } } } cursor } pageInfo { hasNextPage endCursor } } }
# data.path=posts.edges[*].node